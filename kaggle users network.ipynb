{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T09:02:07.937418Z",
     "start_time": "2025-03-07T09:02:07.933902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm as tdqm\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "df7ef713807ab84",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T09:02:08.990345Z",
     "start_time": "2025-03-07T09:02:08.096217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the data\n",
    "teams_df = pd.read_csv('Teams.csv')\n",
    "teams_members_df = pd.read_csv('TeamMemberships.csv')\n",
    "competitions_df = pd.read_csv('competitions.csv')\n",
    "competitions_tags_df = pd.read_csv('CompetitionTags.csv')\n",
    "tags_df = pd.read_csv('Tags.csv')\n",
    "users_teirs_df = pd.read_csv('users.csv',usecols=['Id','PerformanceTier'])\n"
   ],
   "id": "2865802cd96f418",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Load the data\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m teams_df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mTeams.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m teams_members_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTeamMemberships.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      4\u001B[0m competitions_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompetitions.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    625\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 626\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1916\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1917\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1918\u001B[0m     \u001B[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001B[39;00m\n\u001B[0;32m   1919\u001B[0m     (\n\u001B[0;32m   1920\u001B[0m         index,\n\u001B[0;32m   1921\u001B[0m         columns,\n\u001B[0;32m   1922\u001B[0m         col_dict,\n\u001B[1;32m-> 1923\u001B[0m     ) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[attr-defined]\u001B[39;49;00m\n\u001B[0;32m   1924\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnrows\u001B[49m\n\u001B[0;32m   1925\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1926\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1927\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    232\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    233\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlow_memory:\n\u001B[1;32m--> 234\u001B[0m         chunks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_reader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_low_memory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    235\u001B[0m         \u001B[38;5;66;03m# destructive to chunks\u001B[39;00m\n\u001B[0;32m    236\u001B[0m         data \u001B[38;5;241m=\u001B[39m _concatenate_chunks(chunks)\n",
      "File \u001B[1;32mparsers.pyx:838\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:921\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._read_rows\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:1083\u001B[0m, in \u001B[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mparsers.pyx:1456\u001B[0m, in \u001B[0;36mpandas._libs.parsers._maybe_upcast\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\multiarray.py:1131\u001B[0m, in \u001B[0;36mputmask\u001B[1;34m(a, mask, values)\u001B[0m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1083\u001B[0m \u001B[38;5;124;03m    copyto(dst, src, casting='same_kind', where=True)\u001B[39;00m\n\u001B[0;32m   1084\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \n\u001B[0;32m   1127\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (dst, src, where)\n\u001B[1;32m-> 1131\u001B[0m \u001B[38;5;129m@array_function_from_c_func_and_dispatcher\u001B[39m(_multiarray_umath\u001B[38;5;241m.\u001B[39mputmask)\n\u001B[0;32m   1132\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mputmask\u001B[39m(a, \u001B[38;5;241m/\u001B[39m, mask, values):\n\u001B[0;32m   1133\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   1134\u001B[0m \u001B[38;5;124;03m    putmask(a, mask, values)\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1171\u001B[0m \n\u001B[0;32m   1172\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1173\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (a, mask, values)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "teams_df = teams_df[['Id', 'CompetitionId', 'TeamLeaderId']].rename(columns={'Id': 'TeamId'})\n",
    "teams_members_df = teams_members_df[['TeamId', 'UserId']]\n",
    "competitions_df= competitions_df[['Id', 'Slug','DeadlineDate','TotalCompetitors','Title']].rename(columns={'Id': 'CompetitionId'})\n",
    "tags_df= tags_df[['Id', 'Name']].rename(columns={'Id': 'TagId', 'Name': 'TagName'})\n",
    "users_teirs_df = users_teirs_df.rename(columns={'Id': 'UserId'})\n",
    "\n",
    "\n",
    "\n",
    "teams_df = teams_df.dropna()\n",
    "teams_members_df = teams_members_df.dropna()\n",
    "competitions_df = competitions_df.dropna()"
   ],
   "id": "7800638e2d6c6166",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "competitions_df = competitions_df[competitions_df['TotalCompetitors'] !=0]\n",
    "competitions_df = competitions_df.merge(competitions_tags_df[['CompetitionId', 'TagId']], left_on='CompetitionId', right_on='CompetitionId', how='left').drop_duplicates(subset=['CompetitionId'])\n",
    "competitions_df = competitions_df.merge(tags_df[['TagId', 'TagName']], left_on='TagId', right_on='TagId', how='left')\n",
    "competitions_df['TagName']= competitions_df['TagName'].fillna('General')"
   ],
   "id": "b9671c7f95330733",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "competitions_df['TagName'].value_counts()",
   "id": "7533bdad55f71d5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "teams_df['TeamLeaderId'] = teams_df['TeamLeaderId'].astype(int)",
   "id": "81789756045e16f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_to_competition = teams_members_df.merge(\n",
    "    teams_df[['TeamId', 'CompetitionId']], \n",
    "    left_on='TeamId', \n",
    "    right_on='TeamId', \n",
    "    how='left'\n",
    ")\n",
    "user_to_competition = user_to_competition.merge(competitions_df[['CompetitionId', 'Slug','DeadlineDate','TagName','Title']], left_on='CompetitionId', right_on='CompetitionId', how='left')\n",
    "user_to_competition = user_to_competition.merge(users_teirs_df, left_on='UserId', right_on='UserId', how='left')\n"
   ],
   "id": "cd38eb3326f50ddc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_to_competition",
   "id": "4f284f1c2004fbae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#is DeadlineDate a datetime?\n",
    "user_to_competition['DeadlineDate'] = pd.to_datetime(user_to_competition['DeadlineDate'])\n",
    "user_to_competition\n",
    "user_to_competition = user_to_competition[user_to_competition['DeadlineDate'] < '2025-01-01 00:00:00'] \n",
    "user_to_competition"
   ],
   "id": "7436fb9b37bedd2e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#remove inactive competitions\n",
    "single_participation_users = user_to_competition['UserId'].value_counts()\n",
    "single_participation_users = single_participation_users[single_participation_users <2]\n",
    "user_to_competition = user_to_competition[~user_to_competition['UserId'].isin(single_participation_users.index)]\n",
    "user_to_competition"
   ],
   "id": "d83ddb5d4d54d527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "single_participation_competitions = user_to_competition['Slug'].value_counts()\n",
    "single_participation_competitions = single_participation_competitions[single_participation_competitions <2]\n",
    "len(single_participation_competitions)"
   ],
   "id": "a6d2f388b0e633a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "users_set = set(user_to_competition['UserId'])\n",
    "competitions_set = set(user_to_competition['Slug'])"
   ],
   "id": "d1776a3b561189d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_competition = list(zip(user_to_competition['UserId'], user_to_competition['Slug']))",
   "id": "f9a52e68d25511d3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#save the data\n",
    "# user_to_competition.to_csv('user_to_competition.csv', index=False)\n"
   ],
   "id": "875afe3507a5ca00",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## create the network\n",
    "the network is a bipartite graph with two sets of nodes: users and competitions. The edges are the participation of users in competitions."
   ],
   "id": "b09f523311042245"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "network = nx.Graph()\n",
    "# Add nodes\n",
    "network.add_nodes_from(users_set, bipartite=0)\n",
    "network.add_nodes_from(competitions_set, bipartite=1)\n",
    "# Add edges\n",
    "network.add_edges_from(user_competition)\n",
    "#save the network\n",
    "nx.write_graphml(network, 'kaggle_users_network.graphml')"
   ],
   "id": "33811043c87f43f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Network Analysis",
   "id": "120f17bc63f33e05"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'number of nodes: {network.number_of_nodes()}')\n",
    "print(f'number of edges: {network.number_of_edges()}')"
   ],
   "id": "a8a627ca684850ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "nx.is_connected(network)",
   "id": "915ba382afc2b43c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "users, competitions = nx.bipartite.sets(network)",
   "id": "15b7da51750ebbd1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "competitions_degree,users_degree= nx.bipartite.degrees(network, users)\n",
    "competitions_degree= dict(competitions_degree)\n",
    "users_degree = dict(users_degree)"
   ],
   "id": "4cc8be91a7cff1da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import operator\n",
    "print(f'the competition with the highest degree is {max(competitions_degree.items(), key=operator.itemgetter(1))[0]} with a degree of {max(competitions_degree.items(), key=operator.itemgetter(1))[1]}')\n",
    "print(f'the user with the highest degree is {max(users_degree.items(), key=operator.itemgetter(1))[0]} with a degree of {max(users_degree.items(), key=operator.itemgetter(1))[1]}')"
   ],
   "id": "685653df2e76990b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Degree Distribution of competitions",
   "id": "dd0a33270ecd7ce3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot the degree distribution\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert competitions_degree to DataFrame\n",
    "df = pd.DataFrame({'node': list(dict(competitions_degree).keys()), \n",
    "                   'degree': list(dict(competitions_degree).values())})\n",
    "\n",
    "# Create interactive histogram\n",
    "fig = px.histogram(df, x=\"degree\", nbins=1000,\n",
    "                   labels={'degree': 'Node Degree', 'count': 'Frequency'},\n",
    "                   text_auto=True,)\n",
    "\n",
    "# Adjust bar spacing and set y-axis limit\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.update_yaxes(range=[0, 500])  # Limit Y-axis to 100\n",
    "fig.update_xaxes(range=[0, 60000])  # Limit X-axis to 100\n",
    "fig.show()"
   ],
   "id": "a84992e4e9e3229a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert competitions_degree to DataFrame\n",
    "df = pd.DataFrame({'node': list(dict(competitions_degree).keys()), \n",
    "                   'degree': list(dict(competitions_degree).values())})\n",
    "\n",
    "# Extract degree values\n",
    "degree_values = df['degree'].values\n",
    "\n",
    "# Define logarithmic bin edges (smaller bins for small values, larger bins for large values)\n",
    "bins = np.logspace(np.log10(max(1, min(degree_values))), np.log10(max(degree_values)), num=50)\n",
    "\n",
    "# Create histogram with custom bins\n",
    "fig = px.histogram(df, x=\"degree\",\n",
    "                   labels={'degree': 'Node Degree', 'count': 'Frequency'})\n",
    "\n",
    "# Apply custom log-scale bins\n",
    "fig.update_traces(xbins=dict(start=bins[0], end=bins[-1], size=\"auto\"))\n",
    "\n",
    "# Set logarithmic x-axis scale\n",
    "fig.update_xaxes(type=\"log\", title=\"Node Degree (Log Scale)\")\n",
    "fig.update_yaxes( title=\"Frequency\")  # Limit Y-axis to 500\n",
    "\n",
    "fig.show()"
   ],
   "id": "cdf92ad70e6ca572",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Degree Distribution of users\n",
    "\n"
   ],
   "id": "cb352fa006c04317"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#plot the degree distribution\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert competitions_degree to DataFrame\n",
    "df = pd.DataFrame({'node': list(dict(users_degree).keys()), \n",
    "                   'degree': list(dict(users_degree).values())})\n",
    "\n",
    "# Create interactive histogram\n",
    "fig = px.histogram(df, x=\"degree\", nbins=1000, title=\"users Degree Distribution\",\n",
    "                   labels={'degree': 'Node Degree', 'count': 'Frequency'},\n",
    "                   text_auto=True,)\n",
    "\n",
    "# Adjust bar spacing and set y-axis limit\n",
    "fig.update_layout(bargap=0.1)\n",
    "fig.update_yaxes(range=[0, 100])  # Limit Y-axis to 100\n",
    "fig.update_xaxes(range=[0, 5700])  # Limit X-axis to 100\n",
    "fig.show()"
   ],
   "id": "a1f6653f9920565b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert competitions_degree to DataFrame\n",
    "df = pd.DataFrame({'node': list(dict(users_degree).keys()), \n",
    "                   'degree': list(dict(users_degree).values())})\n",
    "\n",
    "# Extract degree values\n",
    "degree_values = df['degree'].values\n",
    "\n",
    "# Define logarithmic bin edges (smaller bins for small values, larger bins for large values)\n",
    "bins = np.logspace(np.log10(max(1, min(degree_values))), np.log10(max(degree_values)), num=50)\n",
    "\n",
    "# Create histogram with custom bins\n",
    "fig = px.histogram(df, x=\"degree\",\n",
    "                   labels={'degree': 'Node Degree', 'count': 'Frequency'})\n",
    "\n",
    "# Apply custom log-scale bins\n",
    "fig.update_traces(xbins=dict(start=bins[0], end=bins[-1], size=\"auto\"))\n",
    "\n",
    "# Set logarithmic x-axis scale\n",
    "fig.update_xaxes(type=\"log\", title=\"Node Degree (Log Scale)\")\n",
    "fig.update_yaxes( title=\"Frequency\")  # Limit Y-axis to 500\n",
    "\n",
    "fig.show()"
   ],
   "id": "b7a4348ab65ce8fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "network = nx.relabel_nodes(network, lambda x: str(x))\n",
    "\n",
    "from networkx.algorithms.community import  louvain_communities\n",
    "#communities = greedy_modularity_communities(network)\n",
    "communities = louvain_communities(network,seed=42)\n",
    "\n",
    "len(communities)"
   ],
   "id": "b6321fe9fff434e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "communities_dict= {}\n",
    "for i in range(len(communities)):\n",
    "    communities_dict[i] = communities[i]"
   ],
   "id": "d771aa6c00b641e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cum_df = pd.DataFrame()\n",
    "for key, value in communities_dict.items():\n",
    "    num_nodes = len(value)\n",
    "    print(f'community {key} has {num_nodes} nodes')\n",
    "    cum_competitions =([node for node in value if node in competitions_set])\n",
    "    print(f'number of competitions in community {key} is {len(cum_competitions)}')\n",
    "    cum_df = pd.concat([cum_df,pd.DataFrame({'community': key,'cumpetitions_number': len(cum_competitions),'number_of_nodes':num_nodes ,}, index=[key])])\n"
   ],
   "id": "3544bc45aab58f75",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Stacked Bar Chart with Log Scale for Number of Nodes\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Apply log transformation to number of nodes to balance visualization\n",
    "cum_df[\"log_number_of_nodes\"] = np.log1p(cum_df[\"number_of_nodes\"])  # log(1 + x) to avoid log(0)\n",
    "\n",
    "# Plot stacked bars\n",
    "bar1 = ax.bar(cum_df[\"community\"], cum_df[\"cumpetitions_number\"], label=\"Competitions\", color='steelblue')\n",
    "bar2 = ax.bar(cum_df[\"community\"], cum_df[\"log_number_of_nodes\"], bottom=cum_df[\"cumpetitions_number\"],\n",
    "              label=\"Log(Number of Nodes)\", color='orange')\n",
    "\n",
    "# Labels & Title\n",
    "ax.set_xlabel(\"Community\")\n",
    "ax.set_ylabel(\"Total Size (Competitions + log(Nodes))\")\n",
    "ax.set_title(\"Stacked Bar Chart: Community Breakdown (Log Scale for Nodes)\")\n",
    "ax.legend()\n",
    "\n",
    "# Display values on bars\n",
    "for bars in [bar1, bar2]:\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        if height > 0:\n",
    "            ax.text(bar.get_x() + bar.get_width() / 2, bar.get_y() + height / 2,\n",
    "                    str(int(height)), ha='center', va='center', fontsize=10, color='black')\n",
    "\n",
    "plt.xticks(cum_df[\"community\"])\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ],
   "id": "91f44f28efcdc70",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_community(community):\n",
    "    subgraph = network.subgraph(community)\n",
    "    print(f\"Graph Type: {type(subgraph)}\")\n",
    "    print(f\"Number of Nodes: {subgraph.number_of_nodes()}\")\n",
    "    print(f\"Number of Edges: {subgraph.number_of_edges()}\")\n",
    "    print(f\"Average Degree: {sum(dict(subgraph.degree()).values()) / subgraph.number_of_nodes():.2f}\") \n",
    "    degree_centrality = nx.degree_centrality(subgraph)\n",
    "    bwtweenness_centrality = nx.betweenness_centrality(subgraph)\n",
    "    closeness_centrality = nx.closeness_centrality(subgraph)\n",
    "    pagerank = nx.pagerank(subgraph)\n",
    "    print((f'the most central node in the community by degree is: {max(degree_centrality.items(), key=operator.itemgetter(1))[0]}'))\n",
    "    print((f'the most central node in the community by betweenness is: {max(bwtweenness_centrality.items(), key=operator.itemgetter(1))[0]}'))\n",
    "    print((f'the most central node in the community by closeness is: {max(closeness_centrality.items(), key=operator.itemgetter(1))[0]}'))\n",
    "    print((f'the most central node in the community by pagerank is: {max(pagerank.items(), key=operator.itemgetter(1))[0]}'))\n",
    "    df = pd.DataFrame({'node': list(degree_centrality.keys()),\n",
    "                       'cummunity_nodes': subgraph.number_of_nodes(),\n",
    "                       'average_degree':sum(dict(subgraph.degree()).values()) / subgraph.number_of_nodes(),\n",
    "                       'degree_centrality': list(degree_centrality.values()),\n",
    "                       'betweenness_centrality': list(bwtweenness_centrality.values()),\n",
    "                       'closeness_centrality': list(closeness_centrality.values()),\n",
    "                       'pagerank': list(pagerank.values())\n",
    "                       })\n",
    "    return df"
   ],
   "id": "873babd8cf54790e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_communities_df = pd.DataFrame()\n",
    "for key, value in communities_dict.items():\n",
    "    print(f'community {key}')\n",
    "    subgraph_df = analyze_community(value)\n",
    "    subgraph_df['community'] = key\n",
    "    all_communities_df = pd.concat([all_communities_df, subgraph_df])"
   ],
   "id": "cadc86c3d27a2cc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "users_in_communities_df = all_communities_df[all_communities_df['node'].isin(users_set)]\n",
    "users_in_communities_df"
   ],
   "id": "8a28723ba42fd0e3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#draw the sub network 4\n",
    "subgraph = network.subgraph(communities_dict[25])\n",
    "\n",
    "# Ensure users_set and subgraph nodes have matching types\n",
    "users_set = {str(node) for node in users_set}  # Convert users_set to strings (if needed)\n",
    "subgraph_nodes = set(subgraph.nodes)\n",
    "\n",
    "# Assign colors based on user type\n",
    "colors = ['blue' if str(node) in users_set else 'red' for node in subgraph_nodes]\n",
    "\n",
    "# Assign node sizes based on degree\n",
    "sizes = [subgraph.degree[node] * 10 for node in subgraph_nodes]  # Scale sizes\n",
    "\n",
    "# Draw the graph\n",
    "plt.figure(figsize=(10, 8))\n",
    "nx.draw(subgraph, with_labels=False, node_color=colors, node_size=sizes, edge_color='gray')\n",
    "\n",
    "plt.show()  # Ensure plot updates"
   ],
   "id": "b673757bb32c3c9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "user_to_competition['UserId']= user_to_competition['UserId'].astype(str)\n",
    "user_to_competition = user_to_competition.merge(all_communities_df[['node', 'community','cummunity_nodes','average_degree','degree_centrality']].rename(columns={'node': 'UserId'}),on='UserId', how='left')\n"
   ],
   "id": "6d11c5512b83e738",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_to_competition[user_to_competition['UserId']=='368']",
   "id": "e6c0bdf9a02e68e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_to_competition",
   "id": "ab41819f75067d71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_to_competition.to_csv('user_to_competition.csv', index=False)",
   "id": "d8c5f71c694f2072",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "user_to_competition.isnull().sum()",
   "id": "a482adc63fef09f6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "data = user_to_competition.drop(columns=['UserId','TagName'])\n",
    "categorical_cols = ['Slug', 'Title']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "data['DeadlineDate'] = data['DeadlineDate'].astype('int64')//10**9\n",
    "\n",
    "## since the performance tier in kaagle is from 1-5 we will remove the 0 tier\n",
    "# data = data[data['PerformanceTier'] !=0]\n",
    "data = data.dropna()\n",
    "X = data.drop(columns=['PerformanceTier'])\n",
    "y = data['PerformanceTier']\n",
    "y.value_counts()"
   ],
   "id": "d79f16e805594409",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ],
   "id": "e5706571c3a51337",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "classificator = LGBMClassifier(n_estimators=500, objective='multiclass')\n",
    "# classificator= RandomForestClassifier(n_estimators=100)\n",
    "classificator.fit(X_train, y_train)\n",
    "pred_classified = classificator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_classified)\n",
    "f1 = f1_score(y_test, pred_classified, average='weighted')"
   ],
   "id": "27fe1e8c99f0845",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, pred_classified)"
   ],
   "id": "6be393874520b8f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'accuracy: {accuracy}')\n",
    "print(f'f1: {f1}')\n",
    "features_importance = classificator.feature_importances_\n",
    "features = X.columns\n",
    "features_importance_df = pd.DataFrame({'feature': features, 'importance': features_importance})\n",
    "features_importance_df = features_importance_df.sort_values(by='importance', ascending=False)"
   ],
   "id": "2cb4507e34aec844",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "reg_model = LGBMRegressor(n_estimators=500)\n",
    "reg_model.fit(X_train, y_train)\n",
    "pred_regressed = reg_model.predict(X_test)"
   ],
   "id": "4b620ef764a5db93",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "mse = mean_squared_error(y_test, pred_regressed)\n",
    "print(f'mse: {mse}')\n",
    "r2 = r2_score(y_test, pred_regressed)\n",
    "print(f'r2: {r2}')"
   ],
   "id": "2f43e4829202370a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "users_max_tier = user_to_competition.merge(max_tier, on='UserId', how='left')\n",
    "users_max_tier"
   ],
   "id": "3cd9837b46e01c9a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "users_max_tier = users_max_tier[users_max_tier['PerformanceTier'] == users_max_tier['MaxTier']]\n",
    "data = users_max_tier.drop(columns=['UserId','TagName','MaxTier'])\n",
    "categorical_cols = ['Slug', 'Title']\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    label_encoders[col] = le\n",
    "data['DeadlineDate'] = data['DeadlineDate'].astype('int64')//10**9\n",
    "\n",
    "## since the performance tier in kaagle is from 1-5 we will remove the 0 tier\n",
    "data = data[data['PerformanceTier'] !=0]\n",
    "data = data.dropna()\n",
    "X = data.drop(columns=['PerformanceTier'])\n",
    "y = data['PerformanceTier']\n",
    "y.value_counts()"
   ],
   "id": "17c33e1b39f636cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "max_classificator = LGBMClassifier(n_estimators=500, objective='multiclass')\n",
    "max_classificator.fit(X_train, y_train)\n",
    "pred_classified = max_classificator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred_classified)\n",
    "f1 = f1_score(y_test, pred_classified, average='weighted')\n"
   ],
   "id": "45f0c00bca36459a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f'accuracy: {accuracy}')\n",
    "print(f'f1: {f1}')\n",
    "features_importance = max_classificator.feature_importances_\n",
    "features = X.columns\n",
    "features_importance_df = pd.DataFrame({'feature': features, 'importance': features_importance})\n",
    "features_importance_df = features_importance_df.sort_values(by='importance', ascending=False)"
   ],
   "id": "b98b5733847c50fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "confusion_matrix(y_test, pred_classified)",
   "id": "808a2c132dbb160",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a92c4ba6e450418",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
